{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Copy of Copy of bert-all.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "02a6443556928bda3f2527b7d803361de3e8e518",
        "id": "rGSiCzyMeLl7",
        "colab_type": "code",
        "outputId": "cf07c33b-57da-4646-d951-cdd6b51d5c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!wget https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n",
        "!wget https://raw.githubusercontent.com/google-research/bert/master/optimization.py \n",
        "!wget https://raw.githubusercontent.com/google-research/bert/master/run_classifier.py \n",
        "!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-03 17:54:19--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.214.128, 2607:f8b0:4001:c05::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.214.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   233MB/s    in 1.7s    \n",
            "\n",
            "2019-09-03 17:54:25 (233 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n",
            "--2019-09-03 17:54:26--  https://raw.githubusercontent.com/google-research/bert/master/modeling.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37922 (37K) [text/plain]\n",
            "Saving to: ‘modeling.py’\n",
            "\n",
            "modeling.py         100%[===================>]  37.03K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-09-03 17:54:26 (3.68 MB/s) - ‘modeling.py’ saved [37922/37922]\n",
            "\n",
            "--2019-09-03 17:54:27--  https://raw.githubusercontent.com/google-research/bert/master/optimization.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6258 (6.1K) [text/plain]\n",
            "Saving to: ‘optimization.py’\n",
            "\n",
            "optimization.py     100%[===================>]   6.11K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-09-03 17:54:28 (86.8 MB/s) - ‘optimization.py’ saved [6258/6258]\n",
            "\n",
            "--2019-09-03 17:54:29--  https://raw.githubusercontent.com/google-research/bert/master/run_classifier.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34783 (34K) [text/plain]\n",
            "Saving to: ‘run_classifier.py’\n",
            "\n",
            "run_classifier.py   100%[===================>]  33.97K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-09-03 17:54:29 (3.32 MB/s) - ‘run_classifier.py’ saved [34783/34783]\n",
            "\n",
            "--2019-09-03 17:54:30--  https://raw.githubusercontent.com/google-research/bert/master/tokenization.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12257 (12K) [text/plain]\n",
            "Saving to: ‘tokenization.py’\n",
            "\n",
            "tokenization.py     100%[===================>]  11.97K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-09-03 17:54:31 (144 MB/s) - ‘tokenization.py’ saved [12257/12257]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "2b1a537730f8d6a59633a18e18443e422a3c7281",
        "id": "4dUScemkeLmD",
        "colab_type": "code",
        "outputId": "68d55b1e-4180-456a-b8d8-a4553488e8f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import modeling\n",
        "import optimization\n",
        "import run_classifier\n",
        "import tokenization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0903 17:54:35.129578 139916593944448 deprecation_wrapper.py:119] From /content/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl59dHbRyBTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1aa95f622d1b59645a9e22c2e6d5d2a5f29a2a50",
        "id": "RDDCfBWBeLmH",
        "colab_type": "code",
        "outputId": "61a636f7-ed43-4019-a4b4-2662fe7e7d6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "!pip install tensorflow\n",
        "!pip install zipfile36\n",
        "import zipfile\n",
        "folder = 'model_folder'\n",
        "with zipfile.ZipFile(\"uncased_L-12_H-768_A-12.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(folder)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.4)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Collecting zipfile36\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/8a/3b7da0b0bd87d1ef05b74207827c72d348b56a0d6d83242582be18a81e02/zipfile36-0.1.3-py3-none-any.whl\n",
            "Installing collected packages: zipfile36\n",
            "Successfully installed zipfile36-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiUBqL8IbA1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QoztoIyao8Q",
        "colab_type": "code",
        "outputId": "ebc90d95-3308-465f-a25d-58565511777b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# Set the output directory for saving model file\n",
        "# Optionally, set a GCP bucket location\n",
        "\n",
        "OUTPUT_DIR = 'OUTPUT_MODEL_80'#@param {type:\"string\"}\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\n",
        "DO_DELETE = True #@param {type:\"boolean\"}\n",
        "#@markdown Set USE_BUCKET and BUCKET if you want to (optionally) store model output on GCP bucket.\n",
        "USE_BUCKET = True #@param {type:\"boolean\"}\n",
        "BUCKET = 'sentiment_data_dawn' #@param {type:\"string\"}\n",
        "\n",
        "if USE_BUCKET:\n",
        "  OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET, OUTPUT_DIR)\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "\n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "  except:\n",
        "    # Doesn't matter if the directory didn't exist\n",
        "    pass\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0903 17:59:38.655646 139916593944448 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: gs://sentiment_data_dawn/OUTPUT_MODEL_80 *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "20541f718c86fed1131409bcc9ee7736d3ec88ac",
        "id": "ABXKomtCeLmO",
        "colab_type": "code",
        "outputId": "31320e11-9d19-421a-8374-771577533ba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "BERT_MODEL = 'uncased_L-12_H-768_A-12'\n",
        "BERT_PRETRAINED_DIR = f'{folder}/uncased_L-12_H-768_A-12'\n",
        "# OUTPUT_DIR = f'{folder}/outputs'\n",
        "print(f'>> Model output directory: {OUTPUT_DIR}')\n",
        "print(f'>>  BERT pretrained directory: {BERT_PRETRAINED_DIR}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> Model output directory: gs://sentiment_data_dawn/OUTPUT_MODEL_80\n",
            ">>  BERT pretrained directory: model_folder/uncased_L-12_H-768_A-12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm_EXtzPjUGq",
        "colab_type": "code",
        "outputId": "e489e285-e048-474c-de30-6c28aa8f9d0e",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4bff8f3e-8b4d-4756-b03b-1ac7ce7053cf\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4bff8f3e-8b4d-4756-b03b-1ac7ce7053cf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train160k.csv to train160k.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rvUQjCKkoxt",
        "colab_type": "code",
        "outputId": "4a6844d6-8980-4945-8dc0-0634a44bef5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# df = pd.read_csv('Tweets.csv', low_memory=False)\n",
        "# df.shape\n",
        "# emo = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
        "# df.airline_sentiment = [emo[item] for item in df.airline_sentiment]\n",
        "# df.airline_sentiment\n",
        "\n",
        "df = pd.read_csv('train160k.csv', encoding = 'latin', low_memory=False, names=['labels','id','date','q','usr','text'])\n",
        "print(type(df.labels))\n",
        "df.dropna(subset=[\"text\"], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "725094e6c9961e294f575672d4ee81449d745b1b",
        "id": "YcG7tdbVeLmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df2 = pd.DataFrame()\n",
        "# df2[\"Text\"] = df[\"text\"]\n",
        "# # df2[\"Label\"] = LabelEncoder().fit_transform(y)\n",
        "# df2[\"Label\"] = df[\"airline_sentiment\"]\n",
        "# df2 = df2[:14640]\n",
        "# df2.head()\n",
        "df2 = pd.DataFrame()\n",
        "df2[\"Text\"] = df[\"text\"]\n",
        "# df2[\"Label\"] = LabelEncoder().fit_transform(y)\n",
        "df2[\"Label\"] = df[\"labels\"]\n",
        "# df2 = df2[:14640]\n",
        "# df2.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7990d9f6cdd2960ebfd61c40c58d3c1acb7d18b6",
        "id": "tPIXEfeveLmb",
        "colab_type": "code",
        "outputId": "53cec8c7-9c08-405a-c0ec-2b85744bb79d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df2[\"Text\"].values, df2[\"Label\"].values, test_size=0.2, random_state=42)\n",
        "X_train = X_train[1:2001]\n",
        "y_train = y_train[1:2001]\n",
        "X_test = X_test[1:1001]\n",
        "y_test = y_test[1:1001]\n",
        "print(X_train.shape,np.sum(y_train))\n",
        "print(X_test.shape,np.sum(y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000,) 996\n",
            "(1000,) 505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkle-U5s191W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1a128c3f38ab69351e34f87977cec04d9d6c9189",
        "id": "5MXWZjXKeLmd",
        "colab_type": "code",
        "outputId": "6ad7de4c-7a3b-483a-8a73-4d0e1a845301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_examples(lines, set_type, labels=None):\n",
        "#Generate data for the BERT model\n",
        "    guid = f'{set_type}'\n",
        "    examples = []\n",
        "    if guid == 'train':\n",
        "        for line, label in zip(lines, labels):\n",
        "            text_a = line\n",
        "            label = str(label)\n",
        "            examples.append(\n",
        "              run_classifier.InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "    else:\n",
        "        for line in lines:\n",
        "            text_a = line\n",
        "            label = '0'\n",
        "            examples.append(\n",
        "              run_classifier.InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
        "    return examples\n",
        "\n",
        "# Model Hyper Parameters\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "EVAL_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 1e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "WARMUP_PROPORTION = 0.1\n",
        "MAX_SEQ_LENGTH = 80\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 100000 #if you wish to finetune a model on a larger dataset, use larger interval\n",
        "# each checpoint weights about 1,5gb\n",
        "ITERATIONS_PER_LOOP = 100000\n",
        "NUM_TPU_CORES = 8\n",
        "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
        "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
        "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
        "DO_LOWER_CASE = BERT_MODEL.startswith('uncased')\n",
        "\n",
        "label_list = [str(num) for num in range(2)]\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)\n",
        "train_examples = create_examples(X_train, 'train', labels=y_train)\n",
        "\n",
        "tpu_cluster_resolver = None #Since training will happen on GPU, we won't need a cluster resolver\n",
        "#TPUEstimator also supports training on CPU and GPU. You don't need to define a separate tf.estimator.Estimator.\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "num_train_steps = int(\n",
        "    len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "model_fn = run_classifier.model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=INIT_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=False, #If False training will fall on CPU or GPU, depending on what is available  \n",
        "    use_one_hot_embeddings=True)\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=False, #If False training will fall on CPU or GPU, depending on what is available \n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0903 19:38:41.686290 139916593944448 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f4083d88950>) includes params argument, but params are not passed to Estimator.\n",
            "W0903 19:38:41.688184 139916593944448 tpu_context.py:211] eval_on_tpu ignored because use_tpu is False.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "e3cb95e4f486c7743add1039f996f501d07109fe",
        "id": "dUSfCeDweLml",
        "colab_type": "code",
        "outputId": "a4123c75-d20c-4a65-9318-0f72210112d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        }
      },
      "source": [
        "import datetime\n",
        "print('Please wait...')\n",
        "train_features = run_classifier.convert_examples_to_features(\n",
        "    train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "print('>> Started training at {} '.format(datetime.datetime.now()))\n",
        "print('  Num examples = {}'.format(len(train_examples)))\n",
        "print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
        "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "train_input_fn = run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=True)\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print('>> Finished training at {}'.format(datetime.datetime.now()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0903 19:38:45.255223 139916593944448 deprecation_wrapper.py:119] From /content/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Please wait...\n",
            ">> Started training at 2019-09-03 19:38:45.768229 \n",
            "  Num examples = 2000\n",
            "  Batch size = 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0903 19:38:47.097332 139916593944448 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0903 19:38:47.691385 139916593944448 deprecation_wrapper.py:119] From /content/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0903 19:38:47.696066 139916593944448 deprecation_wrapper.py:119] From /content/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0903 19:38:47.730457 139916593944448 deprecation_wrapper.py:119] From /content/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0903 19:38:48.117663 139916593944448 deprecation.py:506] From /content/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0903 19:38:48.136916 139916593944448 deprecation.py:323] From /content/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0903 19:38:50.806224 139916593944448 deprecation_wrapper.py:119] From /content/run_classifier.py:647: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0903 19:38:50.813992 139916593944448 deprecation_wrapper.py:119] From /content/run_classifier.py:661: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0903 19:38:51.404843 139916593944448 deprecation_wrapper.py:119] From /content/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0903 19:38:51.406857 139916593944448 deprecation_wrapper.py:119] From /content/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0903 19:38:51.417357 139916593944448 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "W0903 19:38:51.665754 139916593944448 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0903 19:55:23.338437 139916593944448 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 27 vs previous value: 27. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "W0903 20:39:49.095301 139916593944448 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 108 vs previous value: 108. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "W0903 20:42:00.801356 139916593944448 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 112 vs previous value: 112. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "W0903 20:43:07.447450 139916593944448 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 114 vs previous value: 114. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "W0903 20:44:13.086211 139916593944448 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 116 vs previous value: 116. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Finished training at 2019-09-03 21:23:00.624834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "2ed42f193d4586b10b58a65ea06c3d51385160bb",
        "id": "g8D9nni9eLmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_fn_builder(features, seq_length, is_training, drop_remainder):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_segment_ids = []\n",
        "  all_label_ids = []\n",
        "\n",
        "  for feature in features:\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_segment_ids.append(feature.segment_ids)\n",
        "    all_label_ids.append(feature.label_id)\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    print(params)\n",
        "    batch_size = 500\n",
        "\n",
        "    num_examples = len(features)\n",
        "\n",
        "    d = tf.data.Dataset.from_tensor_slices({\n",
        "        \"input_ids\":\n",
        "            tf.constant(\n",
        "                all_input_ids, shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"input_mask\":\n",
        "            tf.constant(\n",
        "                all_input_mask,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"segment_ids\":\n",
        "            tf.constant(\n",
        "                all_segment_ids,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"label_ids\":\n",
        "            tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n",
        "    })\n",
        "\n",
        "    if is_training:\n",
        "      d = d.repeat()\n",
        "      d = d.shuffle(buffer_size=100)\n",
        "\n",
        "    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n",
        "    return d\n",
        "\n",
        "  return input_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ddf519b690697635cbd3b47d2ee875feb94fd822",
        "id": "kRTYtwj6eLmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_examples = create_examples(X_test, 'test')\n",
        "\n",
        "predict_features = run_classifier.convert_examples_to_features(\n",
        "    predict_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "predict_input_fn = input_fn_builder(\n",
        "    features=predict_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)\n",
        "\n",
        "result = estimator.predict(input_fn=predict_input_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "bb9635b3771ecc148b7dc7a2bf4f5de6a8173445",
        "id": "GqYydOMJeLmy",
        "colab_type": "code",
        "outputId": "81b104d6-19e1-49fc-d10f-f523f43b64ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "preds = []\n",
        "for prediction in result:\n",
        "      preds.append(np.argmax(prediction['probabilities']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0903 22:32:36.219150 139916593944448 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f5cc9b9374f73ce94a04b9448e6807976cd89ec0",
        "id": "xzcp-4oUeLm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "de003a2788e27d334232bd515572d73304192fe5",
        "id": "eMdDTXadeLm3",
        "colab_type": "code",
        "outputId": "33de036f-fa58-492a-8f31-0fe1ab77118e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Accuracy of BERT is:\",accuracy_score(y_test,preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of BERT is: 0.8356713426853707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1586642280c06b07158651391f2e80b7756a7a3c",
        "id": "SaM8OhVpeLm7",
        "colab_type": "code",
        "outputId": "f5fe1e83-82e1-45d8-9968-1bf522fa8957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84       258\n",
            "           1       0.83      0.83      0.83       241\n",
            "\n",
            "    accuracy                           0.84       499\n",
            "   macro avg       0.84      0.84      0.84       499\n",
            "weighted avg       0.84      0.84      0.84       499\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "9d77113dca6782b19458f391d1d48769ad1e487a",
        "id": "-QW7fHpbeLm_",
        "colab_type": "code",
        "outputId": "93630c49-c2f5-4f5d-a383-f0c7156dd66e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "pred_sentences = [\n",
        " \"That movie was absolutely awful\",\n",
        " \"The acting was a bit lacking\",\n",
        " \"The film was creative and surprising\",\n",
        " \"Absolutely fantastic!\",\n",
        "   \"Uh....say what?\",\n",
        "   \"No words. Haha\",\n",
        "   \"Kelli Jackson Let's gooooooo.\",\n",
        "   \"NaN\",\n",
        "   \"NaN\",\n",
        "   \"So proud of this man I know! We used to be cadet children. Now he’s an active commander. Fireworks going off! Joshua Reevesyayyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy\",\n",
        "   \"Our son the prodigy\",\n",
        "   \"For anyone who wonders what it was like.\",\n",
        "   \"Alright friends it’s that time of year again. Aaron Burton and I are doing the Tempe Tri, are you in?\",\n",
        "   \"Also my favorite.\",\n",
        "   \"Bringing back an oldie but a goodie. Still my favorite drummer. So skilled.\",\n",
        "   \"This. Is. Gold.\",\n",
        "   \"Maybe someday I can look this cool. Nick Dudzinski\",\n",
        "   \"It’s not just us! I am going to kill you\",\n",
        "   \"The countdown begins!!!!\",\n",
        "   \"Better than morning coffee is this stunna being a drumma.\",\n",
        "   \"Matt Wilson your dance move has been stolen!!!!! Kelli Jackson Garrett Joshua Nail Julia Wilson\",\n",
        "   \"Wonderful Times!\",\n",
        "   \"The food is okay!\",\n",
        "   \"hold on that though, it is horrible\",\n",
        "   \"come on , i dont want to stay here\",\n",
        "   \"Keep it simple, why do I have to tell you always that?\",\n",
        "   \"tell me something, how do i carry this on, it seems impossible!\",\n",
        "   \"I feel better now, thank you\",\n",
        "   \"Please, dont say that!\",\n",
        "   \"check that again\",\n",
        "   \"how did you adapt so easily, I heart that\",\n",
        "   \"The ship has sailed!\",\n",
        "    \"I want to puke!!\",\n",
        "    \"I want to go use my gun for hunting with my dad, I will have such a nice time\",\n",
        "    \"I want to use my gun today at the school\",\n",
        "    \"I am feeling depressed\",\n",
        "    \"I was cyber bullied today,, noone notice it!!!\",\n",
        "    \"I am angry!!!\",\n",
        "    \"what the hell!\",\n",
        "    \"help donate for cancer\",\n",
        "    \"I have cancer\",\n",
        "    \"cancer is my sunsign, I was born in september!\"\n",
        "   \n",
        "]\n",
        "\n",
        "df3_test = np.asarray(pred_sentences)\n",
        "df3_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['That movie was absolutely awful', 'The acting was a bit lacking',\n",
              "       'The film was creative and surprising', 'Absolutely fantastic!',\n",
              "       'Uh....say what?', 'No words. Haha',\n",
              "       \"Kelli Jackson Let's gooooooo.\", 'NaN', 'NaN',\n",
              "       'So proud of this man I know! We used to be cadet children. Now he’s an active commander. Fireworks going off! Joshua Reevesyayyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy',\n",
              "       'Our son the prodigy @kellijacks_',\n",
              "       'For anyone who wonders what it was like.',\n",
              "       'Alright friends it’s that time of year again. Aaron Burton and I are doing the Tempe Tri, are you in?',\n",
              "       'Also my favorite.',\n",
              "       'Bringing back an oldie but a goodie. Still my favorite drummer. So skilled.',\n",
              "       'This. Is. Gold.',\n",
              "       'Maybe someday I can look this cool. Nick Dudzinski',\n",
              "       'Kelli Jackson It’s not just us! I am going to kill you',\n",
              "       'The countdown begins!!!!',\n",
              "       'Better than morning coffee is this stunna being a drumma.',\n",
              "       'Matt Wilson your dance move has been stolen!!!!! Kelli Jackson Garrett Joshua Nail Julia Wilson',\n",
              "       'Wonderful Times!', 'The food is okay!',\n",
              "       'hold on that though, it is horrible',\n",
              "       'come on , i dont want to stay here',\n",
              "       'Keep it simple, why do I have to tell you always that?',\n",
              "       'tell me something, how do i carry this on, it seems impossible!',\n",
              "       'I feel better now, thank you', 'Please, dont say that!',\n",
              "       'check that again', 'how did you adapt so easily, I heart that',\n",
              "       'The ship has sailed!', 'I want to puke!!',\n",
              "       'I want to go use my gun for hunting with my dad, I will have such a nice time',\n",
              "       'I want to use my gun today at the school',\n",
              "       'I am feeling depressed',\n",
              "       'I was cyber bullied today,, noone notice it!!!', 'I am angry!!!',\n",
              "       'what the hell!', 'help donate for cancer', 'I have cancer',\n",
              "       'cancer is my sunsign, I was born in september!'], dtype='<U188')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPviln_rj38B",
        "colab_type": "code",
        "outputId": "afe71ffe-97a4-4c85-dc5e-a2d411b9cdaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!pip install vaderSentiment\n",
        "import vaderSentiment"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/9e/c53e1fc61aac5ee490a6ac5e21b1ac04e55a7c2aba647bb8411c9aadf24e/vaderSentiment-3.2.1-py2.py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 3.5MB/s \n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyxlOAasj2Ef",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_sentences = [\n",
        " \"That movie was absolutely awful\",\n",
        " \"The acting was a bit lacking\",\n",
        " \"The film was creative and surprising\",\n",
        " \"Absolutely fantastic!\",\n",
        "   \"Uh....say what?\",\n",
        "   \"No words. Haha\",\n",
        "   \"Kelli Jackson Let's gooooooo.\",\n",
        "   \"NaN\",\n",
        "   \"NaN\",\n",
        "   \"So proud of this man I know! We used to be cadet children. Now he’s an active commander. Fireworks going off! Joshua Reeves\",\n",
        "   \"Our son the prodigy @kellijacks_\",\n",
        "   \"For anyone who wonders what it was like.\",\n",
        "   \"Alright friends it’s that time of year again. Aaron Burton and I are doing the Tempe Tri, are you in?\",\n",
        "   \"Also my favorite.\",\n",
        "   \"Bringing back an oldie but a goodie. Still my favorite drummer. So skilled.\",\n",
        "   \"This. Is. Gold.\",\n",
        "   \"Maybe someday I can look this cool. Nick Dudzinski\",\n",
        "   \"Kelli Jackson It’s not just us! I am going to kill you\",\n",
        "   \"The countdown begins!!!!\",\n",
        "   \"Better than morning coffee is this stunna being a drumma.\",\n",
        "   \"Matt Wilson your dance move has been stolen!!!!! Kelli Jackson Garrett Joshua Nail Julia Wilson\",\n",
        "   \"Wonderful Times!\",\n",
        "   \"The food is okay!\",\n",
        "   \"hold on that though, it is horrible\",\n",
        "   \"come on , i dont want to stay here\",\n",
        "   \"Keep it simple, why do I have to tell you always that?\",\n",
        "   \"tell me something, how do i carry this on, it seems impossible!\",\n",
        "   \"I feel better now, thank you\",\n",
        "   \"Please, dont say that!\",\n",
        "   \"check that again\",\n",
        "   \"how did you adapt so easily, I heart that\",\n",
        "   \"The ship has sailed!\",\n",
        "   \n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrP2gEDpkJqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "for sentence in pred_sentences:\n",
        "    vs = analyzer.polarity_scores(sentence)\n",
        "    print(\"{:-<65} {}\".format(sentence, str(vs)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeRNivOT3lRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_examples_test = create_examples((df3_test), 'test')\n",
        "\n",
        "predict_features_test = run_classifier.convert_examples_to_features(\n",
        "    predict_examples_test, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "predict_input_fn = input_fn_builder(\n",
        "    features=predict_features_test,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)\n",
        "\n",
        "result_test = estimator.predict(input_fn=predict_input_fn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It_NVtCx2OM2",
        "colab_type": "code",
        "outputId": "d643e390-2eb1-4f6a-cf35-b29c030af879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "preds_test = []\n",
        "for prediction in result_test:\n",
        "      preds_test.append(np.argmax(prediction['probabilities']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0CU_yH_2cG-",
        "colab_type": "code",
        "outputId": "3202b408-4cbc-4998-f5f7-5ffa3d8e8693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "source": [
        "np.shape(preds_test)\n",
        "preds_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_dzc-FH5TxA",
        "colab_type": "code",
        "outputId": "c8829c00-b1ee-457e-eadd-c09b7d0bed42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        }
      },
      "source": [
        "emo_sc = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
        "sc = [emo_sc[item] for item in preds_test]\n",
        "sc\n",
        "for i in range(len(preds_test)):\n",
        "  print(sc[i],pred_sentences[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative That movie was absolutely awful\n",
            "negative The acting was a bit lacking\n",
            "neutral The film was creative and surprising\n",
            "neutral Absolutely fantastic!\n",
            "negative Uh....say what?\n",
            "neutral No words. Haha\n",
            "neutral Kelli Jackson Let's gooooooo.\n",
            "negative NaN\n",
            "negative NaN\n",
            "neutral So proud of this man I know! We used to be cadet children. Now he’s an active commander. Fireworks going off! Joshua Reevesyayyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy\n",
            "neutral Our son the prodigy @kellijacks_\n",
            "neutral For anyone who wonders what it was like.\n",
            "neutral Alright friends it’s that time of year again. Aaron Burton and I are doing the Tempe Tri, are you in?\n",
            "neutral Also my favorite.\n",
            "neutral Bringing back an oldie but a goodie. Still my favorite drummer. So skilled.\n",
            "neutral This. Is. Gold.\n",
            "neutral Maybe someday I can look this cool. Nick Dudzinski\n",
            "negative Kelli Jackson It’s not just us! I am going to kill you\n",
            "neutral The countdown begins!!!!\n",
            "neutral Better than morning coffee is this stunna being a drumma.\n",
            "neutral Matt Wilson your dance move has been stolen!!!!! Kelli Jackson Garrett Joshua Nail Julia Wilson\n",
            "neutral Wonderful Times!\n",
            "neutral The food is okay!\n",
            "negative hold on that though, it is horrible\n",
            "negative come on , i dont want to stay here\n",
            "neutral Keep it simple, why do I have to tell you always that?\n",
            "negative tell me something, how do i carry this on, it seems impossible!\n",
            "neutral I feel better now, thank you\n",
            "negative Please, dont say that!\n",
            "neutral check that again\n",
            "neutral how did you adapt so easily, I heart that\n",
            "neutral The ship has sailed!\n",
            "negative I want to puke!!\n",
            "negative I want to go use my gun for hunting with my dad, I will have such a nice time\n",
            "negative I want to use my gun today at the school\n",
            "negative I am feeling depressed\n",
            "negative I was cyber bullied today,, noone notice it!!!\n",
            "negative I am angry!!!\n",
            "negative what the hell!\n",
            "neutral help donate for cancer\n",
            "negative I have cancer\n",
            "negative cancer is my sunsign, I was born in september!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}